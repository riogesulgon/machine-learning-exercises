{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-9XLkI_m3tE"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C1/W3/ungraded_labs/C1_W3_Lab_2_exploring_convolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJTHvE8Qe5nM"
   },
   "source": [
    "# Ungraded Lab: Exploring Convolutions\n",
    "\n",
    "In this lab, you will explore how convolutions work by creating a basic convolution on a 2D grayscale image. First, you will load the image by taking the [ascent](https://docs.scipy.org/doc/scipy/reference/generated/scipy.datasets.ascent.html) image from [SciPy](https://scipy.org/). It's a nice, built-in picture with lots of angles and lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZ5OXYiolCUi",
    "outputId": "62ca4fb4-4a42-446e-e96d-1151630aed09",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.datasets import ascent\n",
    "\n",
    "# load the ascent image\n",
    "ascent_image = ascent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRIzxjWWfJjk"
   },
   "source": [
    "You can use the pyplot library to draw the image so you'll know what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "R4p0cfWcfIvi",
    "outputId": "410cb475-6195-4bac-a578-066658e21116"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the image\n",
    "plt.grid(False)\n",
    "plt.gray()\n",
    "plt.axis('off')\n",
    "plt.imshow(ascent_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1mhZ_ZTfPWH"
   },
   "source": [
    "The image is stored as a numpy array so you can create the transformed image by first copying that array. You can also get the dimensions of the image so you can loop over it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5pxGq1SmJMD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Copy image to a numpy array\n",
    "image_transformed = np.copy(ascent_image)\n",
    "\n",
    "# Get the dimensions of the image\n",
    "size_x = image_transformed.shape[0]\n",
    "size_y = image_transformed.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7PwNkiXfddd"
   },
   "source": [
    "Now you can create a filter as a 3x3 array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sN3imZannN5J"
   },
   "outputs": [],
   "source": [
    "# Experiment with different values and see the effect\n",
    "# filter = [ [0, 1, 0], [1, -4, 1], [0, 1, 0]]\n",
    "\n",
    "# A couple more filters to try for fun!\n",
    "filter = [ [-1, -2, -1], [0, 0, 0], [1, 2, 1]]\n",
    "# filter = [ [-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n",
    "\n",
    "# If all the digits in the filter don't add up to 0 or 1, you\n",
    "# should probably do a weight to get it to do so\n",
    "# so, for example, if your weights are 1,1,1 1,2,1 1,1,1\n",
    "# They add up to 10, so you would set a weight of .1 if you want to normalize them\n",
    "weight  = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQmm_iBufmCz"
   },
   "source": [
    "Now you can create a convolution. You will iterate over the image, leaving a 1 pixel margin, and multiplying each of the neighbors of the current pixel by the value defined in the filter (i.e. the current pixel's neighbor above it and to the left will be multiplied by the top left item in the filter, etc.)\n",
    "\n",
    "You'll then multiply the result by the weight, and then ensure the result is in the range 0-255.\n",
    "\n",
    "Finally you'll load the new value into the transformed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "299uU2jAr90h"
   },
   "outputs": [],
   "source": [
    "# Iterate over the image\n",
    "for x in range(1,size_x-1):\n",
    "  for y in range(1,size_y-1):\n",
    "      convolution = 0.0\n",
    "      convolution = convolution + (ascent_image[x-1, y-1] * filter[0][0])\n",
    "      convolution = convolution + (ascent_image[x-1, y] * filter[0][1])\n",
    "      convolution = convolution + (ascent_image[x-1, y+1] * filter[0][2])\n",
    "      convolution = convolution + (ascent_image[x, y-1] * filter[1][0])\n",
    "      convolution = convolution + (ascent_image[x, y] * filter[1][1])\n",
    "      convolution = convolution + (ascent_image[x, y+1] * filter[1][2])\n",
    "      convolution = convolution + (ascent_image[x+1, y-1] * filter[2][0])\n",
    "      convolution = convolution + (ascent_image[x+1, y] * filter[2][1])\n",
    "      convolution = convolution + (ascent_image[x+1, y+1] * filter[2][2])\n",
    "\n",
    "      # Multiply by weight\n",
    "      convolution = convolution * weight\n",
    "\n",
    "      # Check the boundaries of the pixel values\n",
    "      if(convolution<0):\n",
    "        convolution=0\n",
    "      if(convolution>255):\n",
    "        convolution=255\n",
    "\n",
    "      # Load into the transformed image\n",
    "      image_transformed[x, y] = convolution"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Convert the image and filter to tensors\n",
    "ascent_image_tensor = tf.convert_to_tensor(ascent_image, dtype=tf.float32)\n",
    "filter_tensor = tf.convert_to_tensor(filter, dtype=tf.float32)\n",
    "\n",
    "# Add extra dimensions needed for the convolution function\n",
    "ascent_image_tensor = tf.expand_dims(tf.expand_dims(ascent_image_tensor, axis=-1), axis=0)\n",
    "filter_tensor = tf.expand_dims(tf.expand_dims(filter_tensor, axis=-1), axis=-1)\n",
    "\n",
    "# Perform the convolution operation\n",
    "convolution = tf.nn.convolution(input=ascent_image_tensor, filters=filter_tensor, padding=\"VALID\")\n",
    "\n",
    "# Multiply by weight\n",
    "convolution = convolution * weight\n",
    "\n",
    "# Check the boundaries of the pixel values\n",
    "convolution = tf.clip_by_value(convolution, clip_value_min=0, clip_value_max=255)\n",
    "\n",
    "# Remove the extra dimensions\n",
    "convolution = tf.squeeze(convolution)\n",
    "\n",
    "# Convert the tensor back to a numpy array\n",
    "image_transformed_tf = convolution.numpy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(filter)\n",
    "# print sum of all values in the filter\n",
    "print(f\"Sum of values in filter is: {np.sum(filter)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "\n",
    "# Define the filter\n",
    "filter = np.array([ [0, 1, 0], [1, -4, 1], [0, 1, 0]], dtype=float)\n",
    "\n",
    "# Apply the filter using convolve function\n",
    "image_transformed = convolve(ascent_image, filter)\n",
    "# Multiply by weight\n",
    "image_transformed = image_transformed * weight\n",
    "\n",
    "# Ensure the pixel values are within the range 0-255\n",
    "image_transformed_scipy = np.clip(image_transformed, 0, 255)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XA--vgvgDEQ"
   },
   "source": [
    "After the loop, you can now plot the image to see the effect of the convolution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "7oPhUPNhuGWC",
    "outputId": "e0deb5da-edcf-46b5-9ed3-b4291116cc00"
   },
   "outputs": [],
   "source": [
    "# Display the original ascent image\n",
    "plt.subplot(1, 4, 1)  # 1 row, 2 columns, index 1\n",
    "plt.grid(False)\n",
    "plt.gray()\n",
    "plt.axis('off')\n",
    "plt.imshow(ascent_image)\n",
    "plt.title('Original Image')\n",
    "\n",
    "# Display the transformed image\n",
    "plt.subplot(1, 4, 2)  # 1 row, 2 columns, index 2\n",
    "plt.grid(False)\n",
    "plt.gray()\n",
    "plt.axis('off')\n",
    "plt.imshow(image_transformed)\n",
    "plt.title('Transformed')\n",
    "\n",
    "# Display the tf transformed image\n",
    "plt.subplot(1, 4, 3)  # 1 row, 2 columns, index 2\n",
    "plt.grid(False)\n",
    "plt.gray()\n",
    "plt.axis('off')\n",
    "plt.imshow(image_transformed)\n",
    "plt.title('tf Image')\n",
    "\n",
    "\n",
    "# Display the scipy transformed image\n",
    "plt.subplot(1, 4, 4)  # 1 row, 2 columns, index 2\n",
    "plt.grid(False)\n",
    "plt.gray()\n",
    "plt.axis('off')\n",
    "plt.imshow(image_transformed_scipy)\n",
    "plt.title('Scipy Image')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xF0FPplsgHNh"
   },
   "source": [
    "## Effect of Max Pooling\n",
    "\n",
    "The next cell will show a (2, 2) pooling. The idea here is to iterate over the image, and look at the pixel and it's immediate neighbors to the right, beneath, and right-beneath. It will take the largest of them and load it into the new image. Thus, the new image will be 1/4 the size of the old -- with the dimensions on X and Y being halved by this process. You'll see that the features get maintained despite this compression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDHjf-ehaBqm"
   },
   "outputs": [],
   "source": [
    "# Assign dimensions half the size of the original image\n",
    "new_x = int(size_x/2)\n",
    "new_y = int(size_y/2)\n",
    "\n",
    "# Create blank image with reduced dimensions\n",
    "newImage = np.zeros((new_x, new_y))\n",
    "\n",
    "# Iterate over the image\n",
    "for x in range(0, size_x, 2):\n",
    "  for y in range(0, size_y, 2):\n",
    "\n",
    "    # Store all the pixel values in the (2,2) pool\n",
    "    pixels = []\n",
    "    pixels.append(image_transformed[x, y])\n",
    "    pixels.append(image_transformed[x+1, y])\n",
    "    pixels.append(image_transformed[x, y+1])\n",
    "    pixels.append(image_transformed[x+1, y+1])\n",
    "\n",
    "    # Get only the largest value and assign to the reduced image\n",
    "    newImage[int(x/2),int(y/2)] = max(pixels)\n",
    "\n",
    "# Plot the image. Note the size of the axes -- it is now 256 pixels instead of 512\n",
    "plt.gray()\n",
    "plt.grid(False)\n",
    "plt.imshow(newImage)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Convert the image and filter to tensors\n",
    "ascent_image_tensor = tf.convert_to_tensor(ascent_image, dtype=tf.float32)\n",
    "filter_tensor = tf.convert_to_tensor(filter, dtype=tf.float32)\n",
    "\n",
    "# Add extra dimensions needed for the convolution function\n",
    "ascent_image_tensor = tf.expand_dims(tf.expand_dims(ascent_image_tensor, axis=-1), axis=0)\n",
    "filter_tensor = tf.expand_dims(tf.expand_dims(filter_tensor, axis=-1), axis=-1)\n",
    "\n",
    "# Perform the convolution operation\n",
    "convolution = tf.nn.convolution(input=ascent_image_tensor, filters=filter_tensor, padding=\"VALID\")\n",
    "\n",
    "# Multiply by weight\n",
    "convolution = convolution * weight\n",
    "\n",
    "# Check the boundaries of the pixel values\n",
    "convolution = tf.clip_by_value(convolution, clip_value_min=0, clip_value_max=255)\n",
    "\n",
    "# Remove the extra dimensions\n",
    "convolution = tf.squeeze(convolution)\n",
    "\n",
    "# Convert the tensor back to a numpy array\n",
    "image_transformed_tf = convolution.numpy()\n",
    "\n",
    "# Perform max pooling operation\n",
    "pool_size = 2\n",
    "pool_stride = 2\n",
    "\n",
    "print(\"Shape of image_transformed_tf (before): \", image_transformed_tf.shape)\n",
    "\n",
    "image_transformed_tf = tf.expand_dims(image_transformed_tf, axis=0) # add batch dimension to start\n",
    "image_transformed_tf = tf.expand_dims(image_transformed_tf, axis=-1) # add channel dimension to end\n",
    "\n",
    "print(\"Shape of image_transformed_tf (after): \", image_transformed_tf.shape)\n",
    "\n",
    "image_pooled = tf.nn.max_pool2d(input=(image_transformed_tf), # NHWC format\n",
    "                                ksize=[1, pool_size, pool_size, 1], \n",
    "                                strides=[1, pool_stride, pool_stride, 1], \n",
    "                                padding='VALID')\n",
    "\n",
    "# Remove the extra dimensions\n",
    "image_pooled = tf.squeeze(image_pooled)\n",
    "\n",
    "# Convert the tensor back to a numpy array\n",
    "image_pooled_np = image_pooled.numpy()\n",
    "\n",
    "# Display the pooled image\n",
    "plt.gray()\n",
    "plt.grid(False)\n",
    "plt.axis('off')\n",
    "plt.imshow(image_pooled_np)\n",
    "plt.title('Pooled Image')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "C1_W3_Lab_2_exploring_convolutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
